###############################################################################
        Patching an MPI implementation to make it PLFS aware
###############################################################################

In order to use PLFS as a ROMIO ADIO layer for MPI_IO, it is necessary to add
PLFS to the ROMIO of the MPI implementation. We are not so much patching MPI
as we are patching a version of the MPICH2 ROMIO layer. ROMIO is maintained in
the MPICH2 package; other MPI implementations such as Open MPI pull a version
of ROMIO from MPICH2 and place it in their own package.

The patching of an MPI implementation to make it PLFS aware requires that two
patches be applied to it. The first patch is one that patches the files that
already exist in the MPI implementation to let the MPI's build process know
about the PLFS layer. This patch is fairly static once developed for a
specific MPI's ROMIO layer. The second patch puts all of the needed PLFS code
in to the MPI implementation. As PLFS changes, this second patch may need to
change. In short, the first patch modifies existing MPI files, the second
patch copies over new files to the MPI implementation.


*** Patching and Building MPI ***

Only Open MPI has been extensively testes with PLFS. Other MPI implementations
should work and some instruction is provided below, but some modifications may
be required. Patches for MPICH2 are included, but are not extensively tested. 
They should also work for any MPICH2 derivative that doesn't modify the path
to the ROMIO layer (such as MVAPICH2).

1) make install of plfs
   a) If you are dealing with a checkout of the PLFS code rather than a
      tarball release, the second patch needs to be generated. Do the
      following to generate the patch (not needed when working from a release
      tarball):
      1) cd <plfs source directory>/mpi_adio
      2) ./scripts/make_ad_plfs_patch
      The default behavior of make_ad_plfs_patch is to create a patch for Open
      MPI. It is possible to create a patch for other MPI implementations.
      This is done by using make_ad_plfs_patch's --mpi command line parameter.
      Please see make_ad_plfs_patch's help for further information.
2) Get the MPI source (<mpi>-<version>)
3) cd <mpi>-<version> (need to be in the top-level source directory for the MPI
   implementation; <mpi> is an MPI implementation like openmpi, mpich2,
   mvapich2, etc.)
4) patch -p1 < /path/to/plfs/mpi_adio/patches/<mpi>/<mpi>-<version>-plfs-prep.patch
   This is the patch that modifies the existing files of an MPI implementation.
   Note that <mpi>-<version>-plfs-prep.patch may not exist for every version.
   There are prep.patch files that work for more than one version of an MPI
   implementation. These will have an 'x' in the version string to help signify
   which versions a particualr patch can be applied to. For example,
   ompi-1.4.x-plfs-pre.patch can be applied to any 1.4.x release such as 1.4.3
   or 1.4.5. Please see what patches are available for the desired MPI
   implementation by looking in patches/<mpi> where <mpi> is the desired MPI.
5) patch -p1 < /path/to/plfs/mpi_adio/patches/<mpi>/<mpi>-plfs.patch
   This patch puts in the PLFS-specific code in to the MPI implementation. It
   should work on any version of the needed MPI implementation.
6) Since some of the templates for the MPI build have been modified by the
   above two patches (such as Makefile.am or Makefile.in), the build scripts
   need to be generated again. This is done by different methods depending on
   the MPI implementation. For convenience, here are methods for doing this
   with Open MPI and MPICH2 at the time of this writing:
   a) for Open MPI:
      ./autogen.sh
   b) for MPICH2 and derivatives:
      ./maint/updatefiles
   Please note that the autotools used for this step be at least the versions
   specified by documentation for that MPI.
7) Check the section labelled "Build Notes for specific versions of MPI" in
   this README to find out if anything special needs to be done for the
   desired MPI.
8) Build MPI: ./configure; make; make install
   The MPI build needs to be able to find libplfs and use it. This is done by
   setting some environment variables and running the configure script.
   a) for Open MPI, set the following env variables

      LDFLAGS="-L/path/to/plfs/lib -Wl,-rpath=/path/to/plfs/lib -lplfs -lstdc++ -lpthread"
      CFLAGS="-I/path/to/plfs/include"
      CXXFLAGS="-I/path/to/plfs/include"
      CCASFLAGS="-I/path/to/plfs/include"

      Then, run configure with like this:

      ./configure --with_io_romio_flags=--with-file-system=ufs+nfs+plfs

      Other flags can be passed to configure such as prefix.
      It is also possible to put the above in a platform file and give that to
      Open MPI's configure process. Please see the Open MPI documentation for
      further information.

   b) for MPICH2 and its derivatives, set the LDFLAGS, CFLAGS, and CXXFLAGS
      env variables as with Open MPI and use the following configure command
      (with possibly more parameters passed to configure such as --prefix):

      ./configure --enable-romio --with-file-system=ufs+nfs+plfs

Here is an example of patching Open MPI 1.4.5 with a checkout of the PLFS code:
cd /path/to/plfs/mpi_adio # Don't need this if I was working with tarball release
./scripts/make_ad_plfs_patch # Don't need this if I was workign with tarball release
cd
tar xjf openmpi-1.4.5.tar.bz2
cd openmpi-1.4.5
patch -p1 < /path/to/plfs/mpi_adio/patches/openmpi/ompi-1.4.x-plfs-prep.patch
patch -p1 < /path/to/plfs/mpi_adio/patches/openmpi/ompi-plfs.patch
./autogen.sh
export LDFLAGS="-L/path/to/plfs/lib -Wl,-rpath=/path/to/plfs/lib -lplfs -lstdc++ -lpthread"
export CFLAGS="-I/path/to/plfs/include"
export CXXFLAGS="-I/path/to/plfs/include"
export CCASFLAGS="-I/path/to/plfs/include"
export CPPFLAGS="-DROMIO_OPENMPI_14x"
./configure --with_io_romio_flags=--with-file-system=ufs+nfs+plfs --prefix=/path/to/mpi/install
make
make install


###############################################################################
Build Notes for specific versions of MPI
###############################################################################
In order for some versions of MPI to build successfully using this version of
PLFS, some additional considerations may be necessary

*** Open MPI 1.4.x ***

The ROMIO in Open MPI 1.4.x is older. Some pieces of the PLFS ADIO code must
be left out. This is done by using the following directive: ROMIO_OPENMPI_14x.
Before running configure, set CPPFLAGS to include this directive:
export CPPFLAGS="-DROMIO_OPENMPI_14x"
